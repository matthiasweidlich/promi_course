{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rules_replay_solution.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matthiasweidlich/promi_course/blob/master/conformance/rules_replay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dGNrw7MDhwr"
      },
      "source": [
        "# Hands-On Exercise: Rule Checking and Replay-based Conformance\n",
        "\n",
        "In this exercise, you will take up the real-life event log of a Dutch financial institute, known already from the earlier notebook. Be reminded that you should be able to fetch the example data with the code in the next cell. If this does not work, however, you can also download the event log (XES format, please unzip) [here](http://www.win.tue.nl/bpi/doku.php?id=2012:challenge) and then either copy it to your google drive, mount it, and read it from there, or directly upload it using your browser.\n",
        "\n",
        "Also, further details can be found in the [description of the dataset](http://www.win.tue.nl/bpi/doku.php?id=2012:challenge)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76CKPHMlDhw3"
      },
      "source": [
        "# basic configuration\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "%matplotlib inline\n",
        "\n",
        "# import data from google drive\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# direct data upload\n",
        "#from google.colab import files\n",
        "#files.upload()\n",
        "\n",
        "# fetch the data file\n",
        "! wget -O financial_log.xes https://github.com/matthiasweidlich/promi_course/blob/master/log_exploration/financial_log.xes?raw=true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAP26A4kDhxN"
      },
      "source": [
        "## Import Event Log\n",
        "The following method imports the log file and returns it in a list structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgalrSbIDhxT"
      },
      "source": [
        "import xml.etree.ElementTree as et\n",
        "\n",
        "def load_xes(file, event_filter = []):\n",
        "    log = []\n",
        "    \n",
        "    tree = et.parse(file)\n",
        "    data = tree.getroot()\n",
        "    \n",
        "    # find all traces\n",
        "    traces = data.findall('{http://www.xes-standard.org/}trace')\n",
        "    \n",
        "    for t in traces:\n",
        "        trace_id = None\n",
        "        \n",
        "        # get trace id\n",
        "        for a in t.findall('{http://www.xes-standard.org/}string'):\n",
        "            if a.attrib['key'] == 'concept:name':\n",
        "                trace_id = a.attrib['value']\n",
        "        \n",
        "        events = []\n",
        "        # events\n",
        "        for event in t.iter('{http://www.xes-standard.org/}event'):\n",
        "            \n",
        "            e = {'name': None, 'timestamp': None, 'resource': None, 'transition': None}\n",
        "            \n",
        "            for a in event:\n",
        "                e[a.attrib['key'].split(':')[1]] = a.attrib['value']\n",
        "            \n",
        "            if e['transition'] == 'COMPLETE' and (e['name'] in event_filter or len(event_filter) == 0):\n",
        "                events.append(e)\n",
        "        \n",
        "        # add trace to log\n",
        "        if len(events) > 0:\n",
        "            log.append({'trace_id': trace_id, 'events': events})\n",
        "        \n",
        "    return log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWx5L0-QDhxj"
      },
      "source": [
        "Now import the given log and compute the trace variants of the log along with their frequencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgiU7VsnDhxm"
      },
      "source": [
        "from pprint import pprint\n",
        "\n",
        "log_file = './financial_log.xes'\n",
        "log = load_xes(log_file)\n",
        "\n",
        "print('Load log with %s traces.' %len(log))\n",
        "\n",
        "trace_variants = {}\n",
        "for trace in log:\n",
        "    events = []\n",
        "    for event in trace['events']:\n",
        "        events.append(event['name'])\n",
        "    trace_variants[tuple(events)] = trace_variants.get(tuple(events), 0) + 1\n",
        "    \n",
        "# print the four most frequent variants\n",
        "trace_variants_sorted_by_freq = sorted(trace_variants.items(), key=lambda kv: kv[1], reverse=True)\n",
        "pprint(trace_variants_sorted_by_freq[:4])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XlqD30dDhx6"
      },
      "source": [
        "\n",
        "## Import Process Model\n",
        "\n",
        "For the log, a process model is given in the form of a Petri net. Such a process model is typically created manually. For this particular example, however, the model has been discovered automatically using the Inductive Miner, applying some noise filtering threshold. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_09nxDhHDhx8"
      },
      "source": [
        "# fetch some python files to model Petri nets\n",
        "! wget -O pn.py https://github.com/matthiasweidlich/promi_course/blob/master/conformance/pn.py?raw=true\n",
        "%run pn.py\n",
        "\n",
        "# fetch the actual definition file of the discovered Petri net \n",
        "! wget -O financial_log_80_noise.pnml https://github.com/matthiasweidlich/promi_course/blob/master/conformance/financial_log_80_noise.pnml?raw=true\n",
        "net = PetriNet()\n",
        "load(net, \"./financial_log_80_noise.pnml\")\n",
        "\n",
        "# mark the initial place\n",
        "net.add_marking(1,1)\n",
        "# visualise it \n",
        "draw_petri_net(net)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQ3HT9SxDhyS"
      },
      "source": [
        "Set up some helper dictionaries to relate transition IDs (from the Petri net) and activity labels to each other. Observe that an activity label is only assigned to a single transition. However, multiple transitions may carry a _tau_ label, representing a silent transition.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qh3g0yFYDhyW"
      },
      "source": [
        "# helper mappings between ids and labels\n",
        "mapping = net.get_mapping()\n",
        "rev_mapping = {}\n",
        "for k, v in net.get_mapping().items():\n",
        "    for k2 in v:\n",
        "        rev_mapping[k2] = k\n",
        "\n",
        "from pprint import pprint\n",
        "# mapping from labels to LISTS of transitions ids\n",
        "pprint(mapping)\n",
        "\n",
        "# mapping from transitions id to label\n",
        "pprint(rev_mapping)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMRGzd_-Dhyn"
      },
      "source": [
        "Next, we illustrate how, given an initial marking, the currently enabled transitions may be identified, how the marking is changed by firing a transition, and how the marking may be adapted to enable a transition. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myJEDGtHDhyt"
      },
      "source": [
        "marking = list(net.get_marking())\n",
        "\n",
        "print(\"Initial marking: \", net.get_marking())\n",
        "\n",
        "enabled = net.all_enabled_transitions()\n",
        "print(\"Enabled transitions in initial marking: \", \n",
        "      list(map((lambda k: rev_mapping[k]), enabled)))\n",
        "\n",
        "# Fire enabled transition (take the first, but there is only one)\n",
        "net.fire_transition(enabled[0])\n",
        "enabled = net.all_enabled_transitions()\n",
        "print(\"Enabled transitions after firing first transition: \", \n",
        "      list(map((lambda k: rev_mapping[k]), enabled)))\n",
        "\n",
        "# Check whether the transition with label 'O_CREATED' is enabled \n",
        "# (there is only one transition carrying this label)\n",
        "print(\"Is transition 'O_CREATED' enabled?\", \n",
        "      net.is_enabled(net.get_mapping()['O_CREATED'][0]))\n",
        "\n",
        "# Enable the transition by changing the marking and adding tokens to the input \n",
        "# places of the transition with label 'O_CREATED' \n",
        "input_places = net.get_input_places(net.get_mapping()['O_CREATED'][0])\n",
        "\n",
        "for p in input_places:\n",
        "    net.add_marking(p,1)\n",
        "\n",
        "# Again, check whether the transition with label 'O_CREATED' is enabled \n",
        "print(\"Is transition 'O_CREATED' enabled after tokens have been added to the places in its preset?\", \n",
        "      net.is_enabled(net.get_mapping()['O_CREATED'][0]))\n",
        "\n",
        "# Check whether further transitions have been enabled by adding the token to \n",
        "# the places in the preset of the transition with label 'O_CREATED'\n",
        "enabled = net.all_enabled_transitions()\n",
        "print(\"Enabled transitions after adapting the marking: \", \n",
        "      list(map((lambda k: rev_mapping[k]), enabled)))\n",
        "\n",
        "print(\"Current marking: \", net.get_marking())\n",
        "\n",
        "for k,v in net.places.items():\n",
        "    net.add_marking(v, marking[k])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-qGA0saGcAB"
      },
      "source": [
        "## Rule Checking\n",
        "\n",
        "First, we assess the conformance of the given event log and process model using rules that are derived from the model. Specifically, we consider a cardinality rule that checks a lower and an upper bound for the number of executions of an activity for a particular trace, as well as an ordering rule that checks whether executions of one activity happen only after executions of another activity.\n",
        "\n",
        "**Task:** Complete the following functions to check the respective rules in a rather generic manner. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rySg4oQQIMMA"
      },
      "source": [
        "def check_lower_bound(trace: [], act: str, bound: int) -> bool:\n",
        "    \n",
        "    ###########################\n",
        "    # Your code here\n",
        "    ###########################\n",
        "\n",
        "    return False\n",
        "\n",
        "def check_upper_bound(trace: [], act: str, bound: int) -> bool:\n",
        "\n",
        "    ###########################\n",
        "    # Your code here\n",
        "    ###########################\n",
        "\n",
        "    return False\n",
        "\n",
        "def check_order_after(trace: [], act_1: str, act_2: str) -> bool:\n",
        "\n",
        "    ###########################\n",
        "    # Your code here\n",
        "    ###########################\n",
        "\n",
        "    return False\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfoHBqWVKD9G"
      },
      "source": [
        "Check whether the five most frequent trace variants actually satisfy the following rules:\n",
        "\n",
        "\n",
        "*   The application is completed at least once (activity \"W_Completeren aanvraag\").\n",
        "*   The application is submitted at most once (activity \"A_SUBMITTED\").\n",
        "*   The income lead (\"W_Afhandelen leads\") is fixed only after the preacceptance (\"A_PREACCEPTED\"), but never before. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZPs7BQNLmN2"
      },
      "source": [
        "for k in range(5):\n",
        "    trace_k = list(trace_variants_sorted_by_freq[k][0])\n",
        "    print(\"Checking trace: %s\" % trace_k)\n",
        "    print(\"Application completed at least once? \", check_lower_bound(trace_k, 'W_Completeren aanvraag', 1))\n",
        "    print(\"Application submitted at most once? \", check_upper_bound(trace_k, 'A_SUBMITTED', 1))\n",
        "    print(\"Fixing income lead only after preaceptance? \", check_order_after(trace_k, 'W_Afhandelen leads', 'A_PREACCEPTED'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szkoNygqDhy7"
      },
      "source": [
        "## Replay-based Conformance\n",
        "\n",
        "Next, consider replay-based conformance checking. \n",
        "\n",
        "**Task:** The following function shall take a Petri net and a trace and replay it. It shall return the numbers of produced, consumed, missing, and remaining tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDUEupg-Dhy-"
      },
      "source": [
        "\n",
        "def replay_trace(net: PetriNet, trace: []) -> (int, int, int, int):\n",
        "   \n",
        "    produced = 1\n",
        "    consumed = 1\n",
        "    missing = 0\n",
        "    remaining = 0\n",
        "\n",
        "    ###########################\n",
        "    # Your code here\n",
        "    ###########################\n",
        "    \n",
        "    return produced, consumed, missing, remaining\n",
        "\n",
        "\n",
        "def fitness(net: PetriNet, log_freq: dict) -> float:\n",
        "    sum_prod = 0\n",
        "    sum_cons = 0\n",
        "    sum_miss = 0\n",
        "    sum_rema = 0\n",
        "\n",
        "    for trace_var, freq in log_freq.items():\n",
        "        # keep copy of marking\n",
        "        marking = list(net.get_marking())\n",
        "        # replay trace\n",
        "        replay_values = replay_trace(net, trace_var)\n",
        "        sum_prod += log_freq[trace_var] * replay_values[0]\n",
        "        sum_cons += log_freq[trace_var] * replay_values[1]\n",
        "        sum_miss += log_freq[trace_var] * replay_values[2]\n",
        "        sum_rema += log_freq[trace_var] * replay_values[3]\n",
        "        # restore marking\n",
        "        for k,v in net.places.items():\n",
        "            net.add_marking(v, marking[k])\n",
        "\n",
        "    return 0.5 * (1 - sum_miss / sum_cons) + 0.5 * (1 - sum_rema / sum_prod)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNe3rwXxDhzI"
      },
      "source": [
        "Measure fitness of the most frequent trace variant: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saN_S2ZnDhzK"
      },
      "source": [
        "log_1 = {t[0]:t[1] for t in trace_variants_sorted_by_freq[0:1]}\n",
        "fitness_value = fitness(net, log_1)\n",
        "print(\"Fitness value of most frequent trace variant:\", fitness_value)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvEh62rADhzX"
      },
      "source": [
        "Now, see how the fitness value changes when considering the _k_-most frequent trace variants."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntNc8c4HDhza"
      },
      "source": [
        "fitness_value = 0\n",
        "for k in range(30):\n",
        "    log_k = {t[0]:t[1] for t in trace_variants_sorted_by_freq[k:k+1]}\n",
        "    log_x = {t[0]:t[1] for t in trace_variants_sorted_by_freq[0:k+1]}\n",
        "    fitness_value_k = fitness(net, log_k)\n",
        "    fitness_value = fitness(net, log_x)\n",
        "    print(\"Fitness value of the single %s-most frequent trace variant: %f\" % (k+1, fitness_value_k))\n",
        "    print(\"Fitness value of %s-most frequent trace variants: %f\" % (k+1, fitness_value))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVHB-fXrGqzI"
      },
      "source": [
        "##-- End"
      ]
    }
  ]
}